{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 检测数据集结构以及样本个数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " └─ 2023_05_16\n",
      "   └─ Tiled_V2\n",
      "     └─ ClearNight\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 227 个 rgb 图片\n",
      "     └─ ClearNoon\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 223 个 rgb 图片\n",
      "     └─ ClearSunset\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 208 个 rgb 图片\n",
      "     └─ WetCloudyNight\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 325 个 rgb 图片\n",
      "     └─ WetCloudyNoon\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 247 个 rgb 图片\n",
      "     └─ WetCloudySunset\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 272 个 rgb 图片\n",
      "   └─ WetRoad1\n",
      "     └─ ClearNight\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 328 个 rgb 图片\n",
      "     └─ ClearNoon\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 238 个 rgb 图片\n",
      "     └─ ClearSunset\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 218 个 rgb 图片\n",
      "     └─ WetCloudyNight\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 255 个 rgb 图片\n",
      "     └─ WetCloudyNoon\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 230 个 rgb 图片\n",
      "     └─ WetCloudySunset\n",
      "       └─ roll0\n",
      "         └─ base05\n",
      "           └─ rgb_front_left: 216 个 rgb 图片\n",
      "\n",
      "所有子文件夹共有 2987 个 rgb 图片\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_gt_images(folder_path):\n",
    "    gt_count = 0\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            gt_count += 1\n",
    "    return gt_count\n",
    "\n",
    "def analyze_dataset(folder_path, level=0):\n",
    "    subfolders = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
    "    total_gt_images = 0\n",
    "\n",
    "    if not subfolders:\n",
    "        if os.path.basename(folder_path) == 'rgb_front_left':\n",
    "            gt_count = count_gt_images(folder_path)\n",
    "            total_gt_images += gt_count\n",
    "            print(f\"{'  ' * level} └─ {os.path.basename(folder_path)}: {gt_count} 个 rgb 图片\")\n",
    "    else:\n",
    "        print(f\"{'  ' * level} └─ {os.path.basename(folder_path)}\")\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)\n",
    "            total_gt_images += analyze_dataset(subfolder_path, level + 1)\n",
    "\n",
    "    return total_gt_images\n",
    "\n",
    "dataset_folder_path = '/media/ljh/data/2023_05_16'\n",
    "total_gt_images = analyze_dataset(dataset_folder_path)\n",
    "print(f\"\\n所有子文件夹共有 {total_gt_images} 个 rgb 图片\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据集划分大致应为：training:validation:testing == 6:1:3\n",
    "### 因此roll-05，roll-10,roll-15,roll0,roll05[base03,06] 一共7042当做训练集\n",
    "### roll05[base09,12,15] 一共1053当做验证集\n",
    "### roll10,roll15 一共3250当做测试集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 手动划分完数据集之后，验证划分是否匹配："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_gt_images(folder_path):\n",
    "    gt_count = 0\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            gt_count += 1\n",
    "    return gt_count\n",
    "\n",
    "def analyze_dataset(folder_path, level=0):\n",
    "    subfolders = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
    "    total_gt_images = 0\n",
    "\n",
    "    if not subfolders:\n",
    "        if os.path.basename(folder_path) == 'rgb_front_left':\n",
    "            gt_count = count_gt_images(folder_path)\n",
    "            total_gt_images += gt_count\n",
    "            print(f\"{'  ' * level} └─ {os.path.basename(folder_path)}: {gt_count} 个 rgb 图片\")\n",
    "    else:\n",
    "        print(f\"{'  ' * level} └─ {os.path.basename(folder_path)}\")\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)\n",
    "            total_gt_images += analyze_dataset(subfolder_path, level + 1)\n",
    "\n",
    "    return total_gt_images\n",
    "\n",
    "dataset_folder_path = '/media/ljh/data/carla_pothole2/carla'\n",
    "subsets_list = [f for f in os.listdir(dataset_folder_path)]\n",
    "train_path, test_path, valid_path = None, None, None\n",
    "\n",
    "for name in subsets_list:\n",
    "    if 'train' in name.lower():\n",
    "        train_path = os.path.join(dataset_folder_path, name)\n",
    "    elif 'val' in name.lower():\n",
    "        valid_path = os.path.join(dataset_folder_path, name)\n",
    "    elif 'test' in name.lower():\n",
    "        test_path = os.path.join(dataset_folder_path, name)\n",
    "\n",
    "assert train_path is not None, \"未找到训练集文件夹\"\n",
    "assert test_path is not None, \"未找到测试集文件夹\"\n",
    "assert valid_path is not None, \"未找到验证集文件夹\"\n",
    "\n",
    "training_image_count = analyze_dataset(train_path)\n",
    "test_image_count = analyze_dataset(test_path)\n",
    "valid_image_count = analyze_dataset(valid_path)\n",
    "\n",
    "print(f\"\\n训练集共有 {training_image_count} 个 rgb 图片\")\n",
    "print(f\"\\n测试集共有 {test_image_count} 个 rgb 图片\")\n",
    "print(f\"\\n验证集共有 {valid_image_count} 个 rgb 图片\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取carla数据集的depth，dispartiy，rgb和gt并且可视化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 读取 depth,normal 文件\n",
    "# depth_file = '/media/ljh/data/carla_pothole2/carla/training/roll0/base03/depth_left/23_849448266.jpeg'\n",
    "# depth_data = cv2.imread(depth_file)[:,:,:]\n",
    "\n",
    "# tmp = np.matmul(depth_data, np.array([65536, 256, 1]))\n",
    "# tmp = np.array(tmp / tmp.max() * 256, dtype=np.int8)\n",
    "# dp = np.array([tmp, tmp, tmp])\n",
    "# # depth_data = dp.swapaxes(0,2).swapaxes(0,1)\n",
    "# # dp = dp.swapaxes(1,2)\n",
    "# depth_data = tmp\n",
    "#\n",
    "# # depth_data = cv2.cvtColor(dp, cv2.COLOR_BGR2RGB)\n",
    "# print('depth.shape:', depth_data.shape, depth_data.dtype)\n",
    "\n",
    "disparity_file = '/media/ljh/data/carla_pothole2/carla/training/roll0/base03/disparity_left/23_849448266.npy'\n",
    "disparity_data = np.load(disparity_file) / 10\n",
    "print('disparity.shape:', disparity_data.shape, disparity_data.dtype)\n",
    "\n",
    "depth_data = 0.3 * 640 / disparity_data\n",
    "# depth_data\n",
    "\n",
    "\n",
    "\n",
    "rgb_file = '/media/ljh/data/carla_pothole2/carla/training/roll0/base03/rgb_front_left/23_849448266.jpeg'\n",
    "rgb_data = cv2.imread(rgb_file)\n",
    "rgb_data = cv2.cvtColor(rgb_data, cv2.COLOR_BGR2RGB)\n",
    "print('rgb.shape:', rgb_data.shape, rgb_data.dtype)\n",
    "\n",
    "gt_file = '/media/ljh/data/carla_pothole2/carla/training/roll0/base03/semantic_segmentation_left/23_849448266.jpeg'\n",
    "gt_data = cv2.imread(gt_file)\n",
    "gt_data = cv2.cvtColor(gt_data, cv2.COLOR_BGR2RGB)\n",
    "print('gt.shape:', gt_data.shape, gt_data.dtype)\n",
    "# 创建子图\n",
    "fig, axes = plt.subplots(4, 1, figsize=(18, 12))\n",
    "\n",
    "axes[0].imshow(depth_data)  # 如果是彩色图像，删除 'cmap' 参数\n",
    "axes[0].set_title('depth Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(disparity_data, cmap='inferno')  # 如果是彩色图像，删除 'cmap' 参数\n",
    "axes[1].set_title('disparity Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(rgb_data)  # 如果是彩色图像，删除 'cmap' 参数\n",
    "axes[2].set_title('rgb Image')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(gt_data)  # 如果是彩色图像，删除 'cmap' 参数\n",
    "axes[3].set_title('rgb Image')\n",
    "axes[3].axis('off')\n",
    "# 显示图像\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 查看gt图片中各个类别所对应的RGB颜色数值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取语义分割图像\n",
    "seg_image_file = '/media/ljh/data/carla_pothole2/carla/training/roll0/base03/semantic_segmentation_left/23_849448266.jpeg'\n",
    "seg_image = cv2.imread(seg_image_file)\n",
    "print(seg_image.shape)\n",
    "# 转换为RGB格式\n",
    "# seg_image_rgb = cv2.cvtColor(seg_image, cv2.COLOR_BGR2RGB)\n",
    "seg_image_rgb = seg_image\n",
    "\n",
    "# 获取所有独特颜色\n",
    "unique_colors = np.unique(seg_image_rgb.reshape(-1, seg_image_rgb.shape[2]), axis=0)\n",
    "print(unique_colors.shape)\n",
    "# 输出独特颜色\n",
    "print(\"Unique labels (RGB):\")\n",
    "for color in unique_colors:\n",
    "    print(color)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我有一个语义分割数据集其文件夹格式如下：\n",
    "├── carla_v2\n",
    "│   ├── 2023_05_16\n",
    "│   │   ├── Tiled_V2\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── semantic_segmentation_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │    ├── ......\n",
    "│   │   │   │    │    │    ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   ├── WetRoad1\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├──1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── semantic_segmentation_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   ├── ......\n",
    "│   ├──2023_05_18_Li\n",
    "│   │   ├── Tiled_V2\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── semantic_segmentation_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │    ├── ......\n",
    "│   │   │   │    │    │    ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   ├── WetRoad1\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├──1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── semantic_segmentation_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   ├── ......\n",
    "对于这个数据集，# 其中每个depth_left子文件夹中的png文件中存了每个样本的深度图，其是一个rgb的uint8格式的图片。在读取每个图片后，我需要通过解码的方式将每个图片的真实深度重新获取。转换的公式如下：\n",
    "depth_data = cv2.imread('/media/ljh/data/2023_05_18_Li/Tiled_V2/ClearNight/roll0/base05/depth_left/3659_863788277.png')\n",
    "scales = np.array([65536.0, 256.0, 1.0])/(256**3 -1)*1000\n",
    "dep_l = np.dot(depth_data, scales).astype(np.float32)  #  获取真实深度3通道float32的图\n",
    "\n",
    "在获取这个真实以米为单位的深度以后，我需要通过特定的深度转法向量算法，将其转换为法向量（3通道，数值在0-1之间的float格式数据）。深度转法向量的代码如下：\n",
    "\n",
    "def depth2normal(depth_data, cam_fx, cam_fy, u0, v0):\n",
    "    # 读取图片高宽\n",
    "    h, w = (720, 1280)\n",
    "\n",
    "    u_map = np.ones((h, 1)) * np.arange(1, w + 1) - u0  # u-u0\n",
    "    v_map = np.arange(1, h + 1).reshape(h, 1) * np.ones((1, w)) - v0  # v-v0\n",
    "    # get depth gradients\n",
    "    Gu, Gv = get_DAG_filter(depth_data)\n",
    "    # Depth to Normal Translation\n",
    "    est_nx = Gu * cam_fx\n",
    "    est_ny = Gv * cam_fy\n",
    "    est_nz = -(depth_data + v_map * Gv + u_map * Gu)\n",
    "    est_normal = cv2.merge((est_nx, est_ny, est_nz))\n",
    "    # vector normalization\n",
    "    est_normal = vector_normalization(est_normal)\n",
    "    # MRF-based Normal Refinement\n",
    "    est_normal = MRF_optim(depth_data, est_normal) # est_normal.dtype float64\n",
    "    # translate interval from [-1,1] to [0,1]\n",
    "    n_vis = (1 - est_normal) / 2\n",
    "\n",
    "    return n_vis\n",
    "\n",
    "cam_fx, cam_fy, u0, v0 = get_cam_params('/home/ljh/Desktop/Workspace/depth-to-normal-translator/figs/params.txt')\n",
    "# 真实深度转换为normal\n",
    "n_vis = depth2normal(dep_l, cam_fx, cam_fy, u0, v0)\n",
    "\n",
    "在获取了法向量信息之后，我希望通过转换，将其保存为uint16的png图片（为了节省磁盘空间，不存成npy），转换的代码如下：\n",
    "\n",
    "n_vis_norm = n_vis\n",
    "\n",
    "n_vis_65535 = np.round(n_vis_norm * 65535).astype(np.uint16)\n",
    "\n",
    "此时获得的n_vis_65535就是uint16的3通道图，我想将其保存成uint16的png图片。\n",
    "现在我需要你根据我给你的代码，结合我的数据集格式，写一个脚本，要求可以将我数据集中所有depth_left文件夹中的所有深度读取，转换成真实深度，再用我提供的算法转换成法向量信息，在得到0-1之间的法向量信息后，将其转换为uin16的png图片保存下来。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我的数据集格式是这样的，在你拿到原数据集中每个样本的名称后，根据这个名称，你需要在备份的数据集文件夹中找到这个名称在disparity_left文件夹中且以.npy结尾的文件，将其放到原数据集中与rgb_front_left,normal_left等模态文件夹同级的disparity_left文件夹中，这样的目的是为了保证数据集中每个样本都不混乱。原数据集的路径：/media/ljh/data/carla_v2。备份数据集的路径：/media/ljh/data/carla_backup/carla_v2。这两个数据集中每个模态的样本都是齐全的，就是组织形式略有区别，所以只能通过文件名字为索引，才能找到对应的disp文件并放到正确的地方。请你根据这些要求，写一份代码：原数据集组织形式\n",
    "├──carla_v2\n",
    "│   ├──training\n",
    "│   │   ├── Tiled_V2\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├──gt_seg\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── tdisp_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── normal_left\n",
    "│   │   │   │    │    │    │   ├── 18_199102858.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │    ├── ......\n",
    "│   │   │   │    │    │    ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   │   ├── ......\n",
    "│   │   ├── WetRoad1\n",
    "│   │   │   ├── ClearNight\n",
    "│   │   │   │   ├── roll0\n",
    "│   │   │   │    │   ├── base05\n",
    "│   │   │   │    │    │   ├── rgb_front_left\n",
    "│   │   │   │    │    │    │   ├──1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── depth_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── semantic_segmentation_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.png\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   │    │    │   ├── disparity_left\n",
    "│   │   │   │    │    │    │   ├── 1068_749841502.npy\n",
    "│   │   │   │    │    │    │   ├── ......\n",
    "│   │   │   ├── ClearNoon\n",
    "│   │   │   ├── ......"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
